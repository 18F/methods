---
layout: card
title: Usability testing
permalink: /validate/usability-testing/
redirect_from:
  - /usability-testing/
description: Observing users as they attempt to use a product or service while thinking out loud.
category: Validate
what: Observing users as they attempt to use a product or service while thinking out loud.
why: To better understand how intuitive the team's design is, and how adaptable it is to meeting user needs.
timeRequired: 30 minutes to 1 hour per test
---

## How to do it

1. Pick what you’ll test. Choose something, such as a sketch, [prototype](/prototyping/), or even a "competitor's product" that might help users accomplish their goals.
1. Plan the test. Setup a meeting and invite anyone who has an interest in what you’d like to test (using your discretion, of course). Align the group on the scenarios the test will center around, which users should participate (and how you'll [recruit](/recruiting/) them), and which members of your team will moderate and observe. Prepare a usability test script ([example](/usability-test-script/)).
1. Recruit users and inform their consent. Provide a way for potential participants to sign up for the test. Pass along to participants an [agreement](/participant-agreement/) explaining what participation will entail. Clarify any logistical expectations, such as screen sharing, and pass along links or files of whatever it is you're testing.
1. Run the tests. Moderators should verbally confirm with the participant that it’s okay to record the test, ask participants to think outloud, and otherwise remain silent.
1. Discuss the results. After each interview, engage your team in a [post-interview debrief](/interview-debrief/). At the end of sessions Maintain a [rolling issues log](/rolling-issues-log/).

<section class="method--section method--section--18f-example" markdown="1" >

## Example from 18F

- [Usability testing plans from 18F's Extractive Industries Transparency Initiative project with Department of the Interior](https://github.com/18F/doi-extractives-data/tree/research/research)
- [Introduction to remote moderated usability testing, part 1&#58; What and why](https://18f.gsa.gov/2018/11/14/introduction-to-remote-moderated-usability-testing-part-1/)
- [Introduction to remote moderated usability testing, part 2&#58; How](https://18f.gsa.gov/2018/11/20/introduction-to-remote-moderated-usability-testing-part-2-how/)


</section>

<section class="method--section method--section--additional-resources" markdown="1">

## Additional resources

- [Interview checklist](/interview-checklist/)
- [Example usability test script](/usability-test-script/)
- [Rolling issues log](/rolling-issues-log/)

</section>

<section class="method--section method--section--government-considerations" markdown="1" >

## Applied in government research

No PRA implications. First, any given usability test should involve nine or fewer users. Additionally, the PRA explicitly exempts direct observation and non-standardized conversation, 5 CFR 1320.3(h)3. It also specifically excludes tests of knowledge or aptitude, 5 CFR 1320.3(h)7, which is essentially what a usability test tests. See the methods for [Recruiting](/recruiting/) and [Privacy](/privacy/) for more tips on taking input from the public.
</section>
